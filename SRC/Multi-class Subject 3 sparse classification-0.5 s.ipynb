{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-07T11:44:17.278191Z",
     "start_time": "2018-06-07T11:44:05.749562Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pyedflib\n",
    "from matplotlib import pyplot as plt\n",
    "from nitime import utils\n",
    "from nitime import algorithms as alg\n",
    "from nitime.timeseries import TimeSeries\n",
    "from nitime.viz import plot_tseries\n",
    "import csv\n",
    "import pywt\n",
    "import scipy.stats as sp\n",
    "from scipy import signal\n",
    "from spectrum import *\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from wyrm import processing as proc\n",
    "from wyrm.types import Data\n",
    "from wyrm.io import convert_mushu_data\n",
    "from sklearn import metrics\n",
    "from wyrm.processing import calculate_csp, segment_dat, apply_csp, append_epo\n",
    "from wyrm.processing import select_channels\n",
    "from wyrm.processing import swapaxes\n",
    "from sklearn.linear_model import OrthogonalMatchingPursuit\n",
    "from sklearn.linear_model import OrthogonalMatchingPursuitCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-07T11:44:17.286885Z",
     "start_time": "2018-06-07T11:44:17.281880Z"
    }
   },
   "outputs": [],
   "source": [
    "channels = [str(i) for i in xrange(1, 61)]\n",
    "data_files_location = 'data_multi/eeg_data'\n",
    "files1 = [f for f in listdir(data_files_location)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-07T11:44:17.429005Z",
     "start_time": "2018-06-07T11:44:17.289497Z"
    }
   },
   "outputs": [],
   "source": [
    "## wavelet features\n",
    "\n",
    "\n",
    "def wavelet_features(epoch):\n",
    "    cA_values = []\n",
    "    cD_values = []\n",
    "    cA_mean = []\n",
    "    cA_std = []\n",
    "    cA_Energy = []\n",
    "    cD_mean = []\n",
    "    cD_std = []\n",
    "    cD_Energy = []\n",
    "    Entropy_D = []\n",
    "    Entropy_A = []\n",
    "    features = []\n",
    "    for i in range(len(epoch)):\n",
    "        cA, cD = pywt.dwt(epoch[i, :], 'coif1')\n",
    "        cA_values.append(cA)\n",
    "        cD_values.append(\n",
    "            cD)  #calculating the coefficients of wavelet transform.\n",
    "    for x in range(len(epoch)):\n",
    "        cA_Energy.append(abs(np.sum(np.square(cA_values[x]))))\n",
    "        features.append(abs(np.sum(np.square(cA_values[x]))))\n",
    "\n",
    "    for x in range(len(epoch)):\n",
    "        cD_Energy.append(abs(np.sum(np.square(cD_values[x]))))\n",
    "        features.append(abs(np.sum(np.square(cD_values[x]))))\n",
    "\n",
    "    for x in range(len(epoch)):\n",
    "        Entropy_D.append(\n",
    "            abs(\n",
    "                np.sum(\n",
    "                    np.square(cD_values[x]) * np.log(np.square(\n",
    "                        cD_values[x])))))\n",
    "        features.append(\n",
    "            abs(\n",
    "                np.sum(\n",
    "                    np.square(cD_values[x]) * np.log(np.square(\n",
    "                        cD_values[x])))))\n",
    "\n",
    "    for x in range(len(epoch)):\n",
    "        Entropy_A.append(\n",
    "            abs(\n",
    "                np.sum(\n",
    "                    np.square(cA_values[x]) * np.log(np.square(\n",
    "                        cA_values[x])))))\n",
    "        features.append(\n",
    "            abs(\n",
    "                np.sum(\n",
    "                    np.square(cA_values[x]) * np.log(np.square(\n",
    "                        cA_values[x])))))\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-07T11:44:17.602650Z",
     "start_time": "2018-06-07T11:44:17.439665Z"
    }
   },
   "outputs": [],
   "source": [
    "## Band Pass features\n",
    "\n",
    "\n",
    "def bandpowers(segment):\n",
    "    features = []\n",
    "    for i in range(len(segment)):\n",
    "        f, Psd = signal.welch(segment[i, :], 100)\n",
    "        power1 = 0\n",
    "        power2 = 0\n",
    "        power3 = 0\n",
    "        f1 = []\n",
    "        for j in range(0, len(f)):\n",
    "            if (f[j] >= 4 and f[j] <= 13):\n",
    "                power1 += Psd[j]\n",
    "            if (f[j] >= 14 and f[j] <= 20):\n",
    "                power2 += Psd[j]\n",
    "            if (f[j] > 20 and f[j] < 30):\n",
    "                power3 += Psd[j]\n",
    "        features.append(power1)\n",
    "        features.append(power2)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-07T11:44:17.738500Z",
     "start_time": "2018-06-07T11:44:17.613743Z"
    }
   },
   "outputs": [],
   "source": [
    "subjects = ['k3b', 'k6b', 'l1b']\n",
    "location = data_files_location + '/' + subjects[1] + '_markers.csv'\n",
    "mark = np.genfromtxt(location, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-07T11:36:37.089867Z",
     "start_time": "2018-06-07T11:35:54.232271Z"
    }
   },
   "outputs": [],
   "source": [
    "##Subject 3\n",
    "sub = 2\n",
    "location_data1 = data_files_location + '/' + subjects[sub] + '_data.csv'\n",
    "location_markers1 = data_files_location + '/' + subjects[sub] + '_markers.csv'\n",
    "\n",
    "data = np.genfromtxt(location_data1, delimiter=\",\")\n",
    "markers = np.genfromtxt(location_markers1, delimiter=\",\")\n",
    "\n",
    "train_markers1 = [(float(events[0]), int(events[1])) for events in markers\n",
    "                  if (events[1] >= 1 and events[1] <= 4)]\n",
    "train_mark_subject1 = []\n",
    "for events in train_markers1:\n",
    "    train_mark_subject1.append((float(events[0]) + 750.0, str(events[1])))\n",
    "    train_mark_subject1.append((float(events[0]) + 875.0, str(events[1])))\n",
    "    train_mark_subject1.append((float(events[0]) + 1000.0, str(events[1])))\n",
    "    train_mark_subject1.append((float(events[0]) + 1125.0, str(events[1])))\n",
    "    train_mark_subject1.append((float(events[0]) + 1250.0, str(events[1])))\n",
    "    train_mark_subject1.append((float(events[0]) + 1375.0, str(events[1])))\n",
    "    train_mark_subject1.append((float(events[0]) + 1500.0, str(events[1])))\n",
    "    train_mark_subject1.append((float(events[0]) + 1625.0, str(events[1])))\n",
    "    #train_mark_subject1.append((float(events[0])+1750.0,str(events[1])))\n",
    "\n",
    "train_mark_subject1 = np.array(train_mark_subject1)\n",
    "\n",
    "markers_subject1_class_1 = [(float(events[0]), events[1])\n",
    "                            for events in train_mark_subject1\n",
    "                            if events[1] == '1']\n",
    "markers_subject1_class_2 = [(float(events[0]), events[1])\n",
    "                            for events in train_mark_subject1\n",
    "                            if events[1] == '2']\n",
    "markers_subject1_class_3 = [(float(events[0]), events[1])\n",
    "                            for events in train_mark_subject1\n",
    "                            if events[1] == '3']\n",
    "markers_subject1_class_4 = [(float(events[0]), events[1])\n",
    "                            for events in train_mark_subject1\n",
    "                            if events[1] == '4']\n",
    "\n",
    "cnt1 = convert_mushu_data(data, markers_subject1_class_1, 125, channels)\n",
    "cnt2 = convert_mushu_data(data, markers_subject1_class_2, 125, channels)\n",
    "cnt3 = convert_mushu_data(data, markers_subject1_class_3, 125, channels)\n",
    "cnt4 = convert_mushu_data(data, markers_subject1_class_4, 125, channels)\n",
    "\n",
    "md = {'class 1': ['1'], 'class 2': ['2'], 'class 3': ['3'], 'class 4': ['4']}\n",
    "\n",
    "epoch_subject1_class1 = segment_dat(cnt1, md, [0, 1000])\n",
    "epoch_subject1_class2 = segment_dat(cnt2, md, [0, 1000])\n",
    "epoch_subject1_class3 = segment_dat(cnt3, md, [0, 1000])\n",
    "epoch_subject1_class4 = segment_dat(cnt4, md, [0, 1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-07T11:36:37.168827Z",
     "start_time": "2018-06-07T11:36:37.093644Z"
    }
   },
   "outputs": [],
   "source": [
    "# Append all epochs\n",
    "\n",
    "class1_epochs = epoch_subject1_class1\n",
    "\n",
    "class2_epochs = epoch_subject1_class2\n",
    "\n",
    "class3_epochs = epoch_subject1_class3\n",
    "\n",
    "class4_epochs = epoch_subject1_class4\n",
    "\n",
    "temp1_epo1 = append_epo(class1_epochs, class2_epochs)\n",
    "temp2_epo2 = append_epo(class3_epochs, class4_epochs)\n",
    "final_epoch = append_epo(temp1_epo1, temp2_epo2)\n",
    "print(final_epoch.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-07T11:36:37.243155Z",
     "start_time": "2018-06-07T11:36:37.172031Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class1_epochs.axes[0].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-07T11:36:53.272202Z",
     "start_time": "2018-06-07T11:36:37.247927Z"
    }
   },
   "outputs": [],
   "source": [
    "## Build the two dictionaries\n",
    "\n",
    "# Dictionary with band power features\n",
    "#form the dictionary using bandpower features where each column is a data point.\n",
    "\n",
    "#For class 1\n",
    "dictionary1 = []\n",
    "dictionary2 = []\n",
    "targets_bp = []\n",
    "targets_we = []\n",
    "for i in range(len(final_epoch.axes[0])):\n",
    "    segment = final_epoch.data[i]\n",
    "    segment = np.array(segment)\n",
    "    segment = np.transpose(segment)\n",
    "\n",
    "    #features = dct_features(segment)\n",
    "    features1 = bandpowers(segment)\n",
    "    #features = logvariance(segment)\n",
    "\n",
    "    features2 = wavelet_features(segment)\n",
    "    f1 = np.array(features1)\n",
    "    f2 = np.array(features2)\n",
    "    if (not (np.isnan(f1).any())):\n",
    "        dictionary1.append(features1)\n",
    "        targets_bp.append(final_epoch.axes[0][i])\n",
    "\n",
    "    if (not (np.isnan(f2).any())):\n",
    "        dictionary2.append(features2)\n",
    "        targets_we.append(final_epoch.axes[0][i])\n",
    "\n",
    "dictionary1 = np.array(dictionary1)\n",
    "dictionary2 = np.array(dictionary2)\n",
    "\n",
    "dictionary_bandpower = dictionary1\n",
    "dictionary_wavelet = dictionary2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-07T11:36:53.291651Z",
     "start_time": "2018-06-07T11:36:53.275052Z"
    }
   },
   "outputs": [],
   "source": [
    "#For wavelet\n",
    "\n",
    "from scipy.sparse import coo_matrix\n",
    "X_sparse = coo_matrix(dictionary_wavelet)\n",
    "\n",
    "from sklearn.utils import resample\n",
    "dictionary_wavelet, X_sparse, y_we = resample(\n",
    "    dictionary_wavelet, X_sparse, targets_we, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-07T11:36:53.451029Z",
     "start_time": "2018-06-07T11:36:53.295693Z"
    }
   },
   "outputs": [],
   "source": [
    "#For Band Power\n",
    "\n",
    "from scipy.sparse import coo_matrix\n",
    "X_sparse = coo_matrix(dictionary_bandpower)\n",
    "\n",
    "from sklearn.utils import resample\n",
    "dictionary_bandpower, X_sparse, y_bp = resample(\n",
    "    dictionary_bandpower, X_sparse, targets_bp, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-07T11:36:53.603840Z",
     "start_time": "2018-06-07T11:36:53.457906Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_accuracy(Xts, yts, D, minimum):\n",
    "    y_pred1 = []\n",
    "    y_pred2 = []\n",
    "    y_pred3 = []\n",
    "    y_pred4 = []\n",
    "    diff = []\n",
    "    class1_avg = 0\n",
    "    class2_avg = 0\n",
    "    class3_avg = 0\n",
    "    class4_avg = 0\n",
    "    counter1 = 0\n",
    "    for i in range(len(Xts)):\n",
    "        features = Xts[i]\n",
    "\n",
    "        omp = OrthogonalMatchingPursuit(n_nonzero_coefs=75)\n",
    "        omp.fit(D, features)\n",
    "        coef = omp.coef_\n",
    "\n",
    "        s1 = 0\n",
    "        s2 = 0\n",
    "        s3 = 0\n",
    "        s4 = 0\n",
    "\n",
    "        l1 = 0\n",
    "        l2 = 0\n",
    "        l3 = 0\n",
    "        l4 = 0\n",
    "\n",
    "        a1 = 0\n",
    "        a2 = 0\n",
    "        a3 = 0\n",
    "        a4 = 0\n",
    "\n",
    "        list1 = coef[0:minimum]\n",
    "        list2 = coef[minimum:2 * minimum]\n",
    "        list3 = coef[2 * minimum:3 * minimum]\n",
    "        list4 = coef[3 * minimum:4 * minimum]\n",
    "\n",
    "        c1 = (sum(z * z for z in list1))**(1 / 2.0)\n",
    "        c2 = (sum(z * z for z in list2))**(1 / 2.0)\n",
    "        c3 = (sum(z * z for z in list3))**(1 / 2.0)\n",
    "        c4 = (sum(z * z for z in list4))**(1 / 2.0)\n",
    "\n",
    "        s1 = np.std(list1)\n",
    "        s2 = np.std(list2)\n",
    "        s3 = np.std(list3)\n",
    "        s4 = np.std(list4)\n",
    "\n",
    "        a1 = max(list1)\n",
    "        a2 = max(list2)\n",
    "        a3 = max(list3)\n",
    "        a4 = max(list4)\n",
    "\n",
    "        for i1 in range(minimum):\n",
    "            l1 = l1 + coef[i1]\n",
    "\n",
    "        for i1 in xrange(minimum, 2 * minimum):\n",
    "            l2 = l2 + coef[i1]\n",
    "\n",
    "        for i1 in range(2 * minimum, 3 * minimum):\n",
    "            l3 = l3 + coef[i1]\n",
    "\n",
    "        for i1 in xrange(3 * minimum, 4 * minimum):\n",
    "            l4 = l4 + coef[i1]\n",
    "\n",
    "        if s1 >= s2 and s1 >= s3 and s1 >= s4:\n",
    "            y_pred1.append(0)\n",
    "        elif s2 >= s1 and s2 >= s3 and s2 >= s4:\n",
    "            y_pred1.append(1)\n",
    "        elif s3 >= s1 and s3 >= s2 and s3 >= s4:\n",
    "            y_pred1.append(2)\n",
    "        else:\n",
    "            y_pred1.append(3)\n",
    "            if (yts[i] == 2):\n",
    "                if (counter1 == 0):\n",
    "                    counter1 += 1\n",
    "                    idx_r, = coef.nonzero()\n",
    "                    plt.xlim(0, len(coef))\n",
    "                    plt.title(\"Sparse Signal\")\n",
    "                    plt.stem(idx_r, coef[idx_r], format='eps', dpi=1000)\n",
    "                    #plt.savefig('Results/With 0.2s /sparse+'counter1'.eps', format='eps', dpi=1000)\n",
    "                    plt.show()\n",
    "\n",
    "        if l1 >= l2 and l1 >= l3 and l1 >= l4:\n",
    "            y_pred2.append(0)\n",
    "        elif l2 >= l1 and l2 >= l3 and l2 >= l4:\n",
    "            y_pred2.append(1)\n",
    "        elif l3 >= l1 and l3 >= l2 and l3 >= l4:\n",
    "            y_pred2.append(2)\n",
    "        else:\n",
    "            y_pred2.append(3)\n",
    "\n",
    "        if a1 >= a2 and a1 >= a3 and a1 >= a4:\n",
    "            y_pred3.append(0)\n",
    "        elif a2 >= a1 and a2 >= a3 and a2 >= a4:\n",
    "            y_pred3.append(1)\n",
    "        elif a3 >= a1 and a3 >= a2 and a3 >= a4:\n",
    "            y_pred3.append(2)\n",
    "        else:\n",
    "            y_pred3.append(3)\n",
    "\n",
    "        if c1 >= c2 and c1 >= c3 and c1 >= c4:\n",
    "            y_pred4.append(0)\n",
    "        elif c2 >= c1 and c2 >= c3 and c2 >= c4:\n",
    "            y_pred4.append(1)\n",
    "        elif c3 >= c1 and c3 >= c2 and c3 >= c4:\n",
    "            y_pred4.append(2)\n",
    "        else:\n",
    "            y_pred4.append(3)\n",
    "\n",
    "    print('class1',\n",
    "          metrics.accuracy_score(\n",
    "              yts, y_pred4, normalize=True, sample_weight=None))\n",
    "    class1_avg += metrics.accuracy_score(\n",
    "        yts, y_pred4, normalize=True, sample_weight=None)\n",
    "\n",
    "    print('class2',\n",
    "          metrics.accuracy_score(\n",
    "              yts, y_pred3, normalize=True, sample_weight=None))\n",
    "    class2_avg += metrics.accuracy_score(\n",
    "        yts, y_pred3, normalize=True, sample_weight=None)\n",
    "\n",
    "    print('class3',\n",
    "          metrics.accuracy_score(\n",
    "              yts, y_pred1, normalize=True, sample_weight=None))\n",
    "    class3_avg += metrics.accuracy_score(\n",
    "        yts, y_pred1, normalize=True, sample_weight=None)\n",
    "\n",
    "    print('class4',\n",
    "          metrics.accuracy_score(\n",
    "              yts, y_pred2, normalize=True, sample_weight=None))\n",
    "    class4_avg += metrics.accuracy_score(\n",
    "        yts, y_pred2, normalize=True, sample_weight=None)\n",
    "\n",
    "    print('\\n')\n",
    "\n",
    "    return y_pred4, y_pred3, y_pred1, y_pred2, class1_avg, class2_avg, class3_avg, class4_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-07T11:37:00.469166Z",
     "start_time": "2018-06-07T11:36:53.607586Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## K fold cross validation on wavelet\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "#dictionary = dictionary_bandpower\n",
    "dictionary = dictionary_wavelet\n",
    "#dictionary = dictionary_dct\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=30, shuffle=True)\n",
    "kf.get_n_splits(dictionary)\n",
    "\n",
    "y = np.array(y_we)\n",
    "\n",
    "y_classifier1 = []\n",
    "y_classifier2 = []\n",
    "y_classifier3 = []\n",
    "y_classifier4 = []\n",
    "\n",
    "avg1 = 0\n",
    "avg2 = 0\n",
    "avg3 = 0\n",
    "avg4 = 0\n",
    "\n",
    "a1 = 0\n",
    "a2 = 0\n",
    "a3 = 0\n",
    "a4 = 0\n",
    "minimum = 0\n",
    "\n",
    "y_all1 = []\n",
    "y_all2 = []\n",
    "y_all3 = []\n",
    "y_all4 = []\n",
    "y_example_test = []\n",
    "\n",
    "reb_dictionary = []\n",
    "\n",
    "y_final_test = []\n",
    "\n",
    "print(kf)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for train_index, test_index in kf.split(dictionary):\n",
    "    X_train, X_test = dictionary[train_index], dictionary[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    class1 = 0\n",
    "    class2 = 0\n",
    "    class3 = 0\n",
    "    class4 = 0\n",
    "    for i in range(len(y_train)):\n",
    "        if (y_train[i] == 0):\n",
    "            class1 += 1\n",
    "        elif (y_train[i] == 1):\n",
    "            class2 += 1\n",
    "        elif (y_train[i] == 2):\n",
    "            class3 += 1\n",
    "        else:\n",
    "            class4 += 1\n",
    "\n",
    "    minimum = min(min(class1, class2), min(class3, class4))\n",
    "    reb_y = []\n",
    "    reb_dic = []\n",
    "    count = 0\n",
    "    iterator = 0\n",
    "    while (count < minimum):\n",
    "        if y_train[iterator] == 0:\n",
    "            reb_dic.append(X_train[iterator])\n",
    "            reb_y.append(0)\n",
    "            count += 1\n",
    "        iterator += 1\n",
    "\n",
    "    count = 0\n",
    "    iterator = 0\n",
    "    while (count < minimum):\n",
    "        if y_train[iterator] == 1:\n",
    "            reb_dic.append(X_train[iterator])\n",
    "            reb_y.append(1)\n",
    "            count += 1\n",
    "        iterator += 1\n",
    "\n",
    "    count = 0\n",
    "    iterator = 0\n",
    "    while (count < minimum):\n",
    "        if y_train[iterator] == 2:\n",
    "            reb_dic.append(X_train[iterator])\n",
    "            reb_y.append(2)\n",
    "            count += 1\n",
    "        iterator += 1\n",
    "\n",
    "    count = 0\n",
    "    iterator = 0\n",
    "    while (count < minimum):\n",
    "        if y_train[iterator] == 3:\n",
    "            reb_dic.append(X_train[iterator])\n",
    "            reb_y.append(3)\n",
    "            count += 1\n",
    "        iterator += 1\n",
    "\n",
    "    reb_dictionary = np.array(reb_dic)\n",
    "    reb_dictionary = reb_dictionary.transpose()\n",
    "\n",
    "    y_classifier1, y_classifier2, y_classifier3, y_classifier4, a1, a2, a3, a4 = calculate_accuracy(\n",
    "        X_test, y_test, reb_dictionary, minimum)\n",
    "\n",
    "    y_all1.extend(y_classifier1)\n",
    "    y_all2.extend(y_classifier2)\n",
    "    y_all3.extend(y_classifier3)\n",
    "    y_all4.extend(y_classifier4)\n",
    "\n",
    "    y_final_test.extend(y_test)\n",
    "\n",
    "    avg1 += a1\n",
    "    avg2 += a2\n",
    "    avg3 += a3\n",
    "    avg4 += a4\n",
    "\n",
    "print('class1_average:', avg1 / 10)\n",
    "print('class2_average:', avg2 / 10)\n",
    "print('class3_average:', avg3 / 10)\n",
    "print('class4_average:', avg4 / 10)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-07T11:37:00.498126Z",
     "start_time": "2018-06-07T11:37:00.473572Z"
    }
   },
   "outputs": [],
   "source": [
    "# Test case running time for 1 test case\n",
    "start_time = time.time()\n",
    "y_classifier1, y_classifier2, y_classifier3, y_classifier4, a1, a2, a3, a4 = calculate_accuracy(\n",
    "    np.reshape(X_test[0], (1, -1)), np.reshape(y_test[0], (1, -1)),\n",
    "    reb_dictionary, minimum)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## K fold cross validation on bandpower\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "dictionary = dictionary_bandpower\n",
    "#dictionary = dictionary_wavelet\n",
    "#dictionary = dictionary_dct\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=30, shuffle=True)\n",
    "kf.get_n_splits(dictionary)\n",
    "\n",
    "y = np.array(y_we)\n",
    "\n",
    "y_classifier1 = []\n",
    "y_classifier2 = []\n",
    "y_classifier3 = []\n",
    "y_classifier4 = []\n",
    "\n",
    "avg1 = 0\n",
    "avg2 = 0\n",
    "avg3 = 0\n",
    "avg4 = 0\n",
    "\n",
    "a1 = 0\n",
    "a2 = 0\n",
    "a3 = 0\n",
    "a4 = 0\n",
    "minimum = 0\n",
    "\n",
    "y_all1 = []\n",
    "y_all2 = []\n",
    "y_all3 = []\n",
    "y_all4 = []\n",
    "y_example_test = []\n",
    "\n",
    "reb_dictionary = []\n",
    "\n",
    "y_final_test = []\n",
    "\n",
    "print(kf)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for train_index, test_index in kf.split(dictionary):\n",
    "    X_train, X_test = dictionary[train_index], dictionary[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    class1 = 0\n",
    "    class2 = 0\n",
    "    class3 = 0\n",
    "    class4 = 0\n",
    "    for i in range(len(y_train)):\n",
    "        if (y_train[i] == 0):\n",
    "            class1 += 1\n",
    "        elif (y_train[i] == 1):\n",
    "            class2 += 1\n",
    "        elif (y_train[i] == 2):\n",
    "            class3 += 1\n",
    "        else:\n",
    "            class4 += 1\n",
    "\n",
    "    minimum = min(min(class1, class2), min(class3, class4))\n",
    "    reb_y = []\n",
    "    reb_dic = []\n",
    "    count = 0\n",
    "    iterator = 0\n",
    "    while (count < minimum):\n",
    "        if y_train[iterator] == 0:\n",
    "            reb_dic.append(X_train[iterator])\n",
    "            reb_y.append(0)\n",
    "            count += 1\n",
    "        iterator += 1\n",
    "\n",
    "    count = 0\n",
    "    iterator = 0\n",
    "    while (count < minimum):\n",
    "        if y_train[iterator] == 1:\n",
    "            reb_dic.append(X_train[iterator])\n",
    "            reb_y.append(1)\n",
    "            count += 1\n",
    "        iterator += 1\n",
    "\n",
    "    count = 0\n",
    "    iterator = 0\n",
    "    while (count < minimum):\n",
    "        if y_train[iterator] == 2:\n",
    "            reb_dic.append(X_train[iterator])\n",
    "            reb_y.append(2)\n",
    "            count += 1\n",
    "        iterator += 1\n",
    "\n",
    "    count = 0\n",
    "    iterator = 0\n",
    "    while (count < minimum):\n",
    "        if y_train[iterator] == 3:\n",
    "            reb_dic.append(X_train[iterator])\n",
    "            reb_y.append(3)\n",
    "            count += 1\n",
    "        iterator += 1\n",
    "\n",
    "    reb_dictionary = np.array(reb_dic)\n",
    "    reb_dictionary = reb_dictionary.transpose()\n",
    "\n",
    "    y_classifier1, y_classifier2, y_classifier3, y_classifier4, a1, a2, a3, a4 = calculate_accuracy(\n",
    "        X_test, y_test, reb_dictionary, minimum)\n",
    "\n",
    "    y_all1.extend(y_classifier1)\n",
    "    y_all2.extend(y_classifier2)\n",
    "    y_all3.extend(y_classifier3)\n",
    "    y_all4.extend(y_classifier4)\n",
    "\n",
    "    y_final_test.extend(y_test)\n",
    "\n",
    "    avg1 += a1\n",
    "    avg2 += a2\n",
    "    avg3 += a3\n",
    "    avg4 += a4\n",
    "\n",
    "print('class1_average:', avg1 / 10)\n",
    "print('class2_average:', avg2 / 10)\n",
    "print('class3_average:', avg3 / 10)\n",
    "print('class4_average:', avg4 / 10)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot confusion matrix\n",
    "\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm,\n",
    "                          classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Greens):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(\n",
    "            j,\n",
    "            i,\n",
    "            cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf_matrix = confusion_matrix(y_final_test, y_all4)\n",
    "np.set_printoptions(precision=2)\n",
    "class_names = [\"Left\", \"Right\", \"Foot\", \"Tongue\"]\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(\n",
    "    cnf_matrix,\n",
    "    classes=class_names,\n",
    "    title='Confusion matrix, without normalization')\n",
    "#plt.savefig('Results/With 0.2s /CM_WN_S3.eps', format='eps', dpi=1000)\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(\n",
    "    cnf_matrix,\n",
    "    classes=class_names,\n",
    "    normalize=True,\n",
    "    title='Normalized confusion matrix')\n",
    "#plt.savefig('Results/With 0.2s /CM_N_S3.eps', format='eps', dpi=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot ROC curve\n",
    "\n",
    "count = 0\n",
    "iterator = 0\n",
    "real0 = []\n",
    "pred0 = []\n",
    "\n",
    "real1 = []\n",
    "pred1 = []\n",
    "\n",
    "real2 = []\n",
    "pred2 = []\n",
    "\n",
    "real3 = []\n",
    "pred3 = []\n",
    "\n",
    "while (iterator < len(y_final_test)):\n",
    "    if (y_final_test[iterator] == 0):\n",
    "        real0.append(0)\n",
    "        if (y_all1[iterator] == 0):\n",
    "            pred0.append(0)\n",
    "        else:\n",
    "            pred0.append(1)\n",
    "    else:\n",
    "        real0.append(1)\n",
    "        if (y_all1[iterator] == 0):\n",
    "            pred0.append(0)\n",
    "        else:\n",
    "            pred0.append(1)\n",
    "    iterator += 1\n",
    "\n",
    "iterator = 0\n",
    "while (iterator < len(y_final_test)):\n",
    "    if (y_final_test[iterator] == 1):\n",
    "        real1.append(1)\n",
    "        if (y_all1[iterator] == 1):\n",
    "            pred1.append(1)\n",
    "        else:\n",
    "            pred1.append(0)\n",
    "    else:\n",
    "        real1.append(0)\n",
    "        if (y_all1[iterator] == 1):\n",
    "            pred1.append(1)\n",
    "        else:\n",
    "            pred1.append(0)\n",
    "    iterator += 1\n",
    "\n",
    "iterator = 0\n",
    "while (iterator < len(y_final_test)):\n",
    "    if (y_final_test[iterator] == 2):\n",
    "        real2.append(1)\n",
    "        if (y_all1[iterator] == 2):\n",
    "            pred2.append(1)\n",
    "        else:\n",
    "            pred2.append(0)\n",
    "    else:\n",
    "        real2.append(0)\n",
    "        if (y_all1[iterator] == 2):\n",
    "            pred2.append(1)\n",
    "        else:\n",
    "            pred2.append(0)\n",
    "    iterator += 1\n",
    "\n",
    "iterator = 0\n",
    "while (iterator < len(y_final_test)):\n",
    "    if (y_final_test[iterator] == 3):\n",
    "        real3.append(1)\n",
    "        if (y_all1[iterator] == 3):\n",
    "            pred3.append(1)\n",
    "        else:\n",
    "            pred3.append(0)\n",
    "    else:\n",
    "        real3.append(0)\n",
    "        if (y_all1[iterator] == 3):\n",
    "            pred3.append(1)\n",
    "        else:\n",
    "            pred3.append(0)\n",
    "    iterator += 1\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from scipy import interp\n",
    "\n",
    "fpr, tpr, _ = roc_curve(real0, pred0)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "fpr1, tpr1, _ = roc_curve(real1, pred1)\n",
    "roc_auc1 = auc(fpr1, tpr1)\n",
    "\n",
    "fpr2, tpr2, _ = roc_curve(real2, pred2)\n",
    "roc_auc2 = auc(fpr2, tpr2)\n",
    "\n",
    "fpr3, tpr3, _ = roc_curve(real3, pred3)\n",
    "roc_auc3 = auc(fpr3, tpr3)\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(\n",
    "    fpr,\n",
    "    tpr,\n",
    "    color='blue',\n",
    "    lw=lw,\n",
    "    label='Left class ROC curve (area = %0.2f)' % roc_auc)\n",
    "\n",
    "plt.plot(\n",
    "    fpr1,\n",
    "    tpr1,\n",
    "    color='green',\n",
    "    lw=lw,\n",
    "    label='Right class ROC curve (area = %0.2f)' % roc_auc1)\n",
    "\n",
    "plt.plot(\n",
    "    fpr2,\n",
    "    tpr2,\n",
    "    color='red',\n",
    "    lw=lw,\n",
    "    label='Foot class ROC curve (area = %0.2f)' % roc_auc2)\n",
    "\n",
    "plt.plot(\n",
    "    fpr3,\n",
    "    tpr3,\n",
    "    color='yellow',\n",
    "    lw=lw,\n",
    "    label='Tongue class ROC curve (area = %0.2f)' % roc_auc3)\n",
    "plt.plot([0, 1], [0, 1], color='darkorange', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "#plt.savefig('Results/With 0.2s /ROC_S3.eps', format='eps', dpi=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot precision recall curve\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from itertools import cycle\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "# Compute Precision-Recall and plot curve\n",
    "precision = []\n",
    "recall = []\n",
    "average_precision = []\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(real0, pred0)\n",
    "\n",
    "average_precision = average_precision_score(real0, pred0)\n",
    "\n",
    "precision1, recall1, thresholds1 = precision_recall_curve(real1, pred1)\n",
    "\n",
    "average_precision1 = average_precision_score(real1, pred1)\n",
    "\n",
    "precision2, recall2, thresholds2 = precision_recall_curve(real2, pred2)\n",
    "\n",
    "average_precision2 = average_precision_score(real2, pred2)\n",
    "\n",
    "precision3, recall3, thresholds3 = precision_recall_curve(real3, pred3)\n",
    "\n",
    "average_precision3 = average_precision_score(real3, pred3)\n",
    "\n",
    "# Plot Precision-Recall curve\n",
    "plt.clf()\n",
    "plt.plot(\n",
    "    recall,\n",
    "    precision,\n",
    "    lw=lw,\n",
    "    color='blue',\n",
    "    label='Left class Precision-recall curve (area = {0:0.2f})'\n",
    "    ''.format(average_precision))\n",
    "\n",
    "plt.plot(\n",
    "    recall1,\n",
    "    precision1,\n",
    "    lw=lw,\n",
    "    color='green',\n",
    "    label='Right class Precision-recall curve (area = {0:0.2f})'\n",
    "    ''.format(average_precision1))\n",
    "\n",
    "plt.plot(\n",
    "    recall2,\n",
    "    precision2,\n",
    "    lw=lw,\n",
    "    color='red',\n",
    "    label='Foot class Precision-recall curve (area = {0:0.2f})'\n",
    "    ''.format(average_precision2))\n",
    "\n",
    "plt.plot(\n",
    "    recall3,\n",
    "    precision3,\n",
    "    lw=lw,\n",
    "    color='yellow',\n",
    "    label='Tongue class Precision-recall curve (area = {0:0.2f})'\n",
    "    ''.format(average_precision3))\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title(\"Precision Recall Curve\")\n",
    "\n",
    "plt.legend(loc=\"lower left\")\n",
    "#plt.savefig('Results/With 0.2s /PR_S3.eps', format='eps', dpi=1000)\n",
    "plt.show()\n",
    "#plt.savefig('precision_S3.eps', format='eps', dpi=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
