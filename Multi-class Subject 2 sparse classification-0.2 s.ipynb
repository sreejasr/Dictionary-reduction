{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pyedflib\n",
    "from matplotlib import pyplot as plt\n",
    "from nitime import utils\n",
    "from nitime import algorithms as alg\n",
    "from nitime.timeseries import TimeSeries\n",
    "from nitime.viz import plot_tseries\n",
    "import csv\n",
    "import pywt\n",
    "import scipy.stats as sp\n",
    "from scipy import signal\n",
    "from spectrum import *\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from wyrm import processing as proc\n",
    "from wyrm.types import Data\n",
    "from wyrm.io import convert_mushu_data\n",
    "from sklearn import metrics\n",
    "from wyrm.processing import calculate_csp,segment_dat,apply_csp,append_epo\n",
    "from wyrm.processing import select_channels\n",
    "from wyrm.processing import swapaxes\n",
    "from sklearn.linear_model import OrthogonalMatchingPursuit\n",
    "from sklearn.linear_model import OrthogonalMatchingPursuitCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "channels = [str(i) for i in xrange(1,61)]\n",
    "data_files_location = '4_class_data'\n",
    "files1  = [f for f in listdir(data_files_location)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## wavelet features\n",
    "\n",
    "def wavelet_features(epoch):\n",
    "    cA_values = []\n",
    "    cD_values = []\n",
    "    cA_mean = []\n",
    "    cA_std = []\n",
    "    cA_Energy =[]\n",
    "    cD_mean = []\n",
    "    cD_std = []\n",
    "    cD_Energy = []\n",
    "    Entropy_D = []\n",
    "    Entropy_A = []\n",
    "    features = []\n",
    "    for i in range(len(epoch)):\n",
    "        cA,cD=pywt.dwt(epoch[i,:],'coif1')\n",
    "        cA_values.append(cA)\n",
    "        cD_values.append(cD)\t\t#calculating the coefficients of wavelet transform.\n",
    "    for x in range(len(epoch)):   \n",
    "        cA_Energy.append(abs(np.sum(np.square(cA_values[x]))))\n",
    "        features.append(abs(np.sum(np.square(cA_values[x]))))\n",
    "        \n",
    "    for x in range(len(epoch)):      \n",
    "        cD_Energy.append(abs(np.sum(np.square(cD_values[x]))))\n",
    "        features.append(abs(np.sum(np.square(cD_values[x]))))\n",
    "        \n",
    "    for x in range(len(epoch)):\n",
    "        Entropy_D.append(abs(np.sum(np.square(cD_values[x]) * np.log(np.square(cD_values[x])))))\n",
    "        features.append(abs(np.sum(np.square(cD_values[x]) * np.log(np.square(cD_values[x])))))\n",
    "    \n",
    "    for x in range(len(epoch)):\n",
    "        Entropy_A.append(abs(np.sum(np.square(cA_values[x]) * np.log(np.square(cA_values[x]))))) \n",
    "        features.append(abs(np.sum(np.square(cA_values[x]) * np.log(np.square(cA_values[x])))))\n",
    "        \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Band Pass features\n",
    "\n",
    "def bandpowers(segment):\n",
    "    features = []\n",
    "    for i in range(len(segment)):\n",
    "        f,Psd = signal.welch(segment[i,:], 100)\n",
    "        power1 = 0\n",
    "        power2 = 0\n",
    "        power3 = 0\n",
    "        f1 = []\n",
    "        for j in range(0,len(f)):\n",
    "            if(f[j]>=4 and f[j]<=13):\n",
    "                power1 += Psd[j]\n",
    "            if(f[j]>=14 and f[j]<=20):\n",
    "                power2 += Psd[j]\n",
    "            if(f[j]>20 and f[j]<30):\n",
    "                power3 += Psd[j]\n",
    "        features.append(power1)\n",
    "        features.append(power2)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subjects = ['k3b','k6b','l1b']\n",
    "location = data_files_location + '/' + subjects[1] + '_markers.csv'\n",
    "mark = np.genfromtxt (location, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Subject 2\n",
    "\n",
    "location_data1  = data_files_location + '/' + subjects[1] + '_data.csv'\n",
    "location_markers1 = data_files_location + '/' + subjects[1] + '_markers.csv'\n",
    "        \n",
    "data = np.genfromtxt (location_data1, delimiter=\",\")\n",
    "markers = np.genfromtxt (location_markers1, delimiter = \",\")\n",
    "\n",
    "train_markers1 = [(float(events[0]),int(events[1])) for events in markers if (events[1]>=1 and events[1]<=4)]\n",
    "train_mark_subject1 = []\n",
    "for events in train_markers1:\n",
    "    train_mark_subject1.append((float(events[0])+750.0,str(events[1])))\n",
    "    train_mark_subject1.append((float(events[0])+800.0,str(events[1])))\n",
    "    train_mark_subject1.append((float(events[0])+850.0,str(events[1])))\n",
    "    train_mark_subject1.append((float(events[0])+900.0,str(events[1])))\n",
    "    train_mark_subject1.append((float(events[0])+950.0,str(events[1])))\n",
    "    train_mark_subject1.append((float(events[0])+1000.0,str(events[1])))\n",
    "    train_mark_subject1.append((float(events[0])+1050.0,str(events[1])))\n",
    "    train_mark_subject1.append((float(events[0])+1100.0,str(events[1])))\n",
    "    train_mark_subject1.append((float(events[0])+1150.0,str(events[1])))\n",
    "    train_mark_subject1.append((float(events[0])+1200.0,str(events[1])))\n",
    "    train_mark_subject1.append((float(events[0])+1250.0,str(events[1])))\n",
    "    train_mark_subject1.append((float(events[0])+1300.0,str(events[1])))\n",
    "    train_mark_subject1.append((float(events[0])+1350.0,str(events[1])))\n",
    "    train_mark_subject1.append((float(events[0])+1400.0,str(events[1])))\n",
    "    train_mark_subject1.append((float(events[0])+1450.0,str(events[1])))\n",
    "    train_mark_subject1.append((float(events[0])+1500.0,str(events[1])))\n",
    "    train_mark_subject1.append((float(events[0])+1550.0,str(events[1])))\n",
    "    train_mark_subject1.append((float(events[0])+1600.0,str(events[1])))\n",
    "    train_mark_subject1.append((float(events[0])+1650.0,str(events[1])))\n",
    "    train_mark_subject1.append((float(events[0])+1700.0,str(events[1])))\n",
    "    #train_mark_subject1.append((float(events[0])+1750.0,str(events[1])))\n",
    "       \n",
    "train_mark_subject1 = np.array(train_mark_subject1)\n",
    "\n",
    "markers_subject1_class_1 = [(float(events[0]),events[1]) for events in train_mark_subject1 if events[1]== '1']\n",
    "markers_subject1_class_2 = [(float(events[0]),events[1]) for events in train_mark_subject1 if events[1]== '2']\n",
    "markers_subject1_class_3 = [(float(events[0]),events[1]) for events in train_mark_subject1 if events[1]== '3']\n",
    "markers_subject1_class_4 = [(float(events[0]),events[1]) for events in train_mark_subject1 if events[1]== '4']\n",
    "\n",
    "cnt1 = convert_mushu_data(data, markers_subject1_class_1,50,channels)\n",
    "cnt2 = convert_mushu_data(data, markers_subject1_class_2,50,channels)\n",
    "cnt3 = convert_mushu_data(data, markers_subject1_class_3,50,channels)\n",
    "cnt4 = convert_mushu_data(data, markers_subject1_class_4,50,channels)\n",
    "\n",
    "md = {'class 1': ['1'],'class 2': ['2'],'class 3' : ['3'],'class 4' : ['4']}\n",
    "\n",
    "epoch_subject1_class1 = segment_dat(cnt1, md, [0, 1000])\n",
    "epoch_subject1_class2 = segment_dat(cnt2, md, [0, 1000])\n",
    "epoch_subject1_class3 = segment_dat(cnt3, md, [0, 1000])\n",
    "epoch_subject1_class4 = segment_dat(cnt4, md, [0, 1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Append all epochs\n",
    "\n",
    "class1_epochs = epoch_subject1_class1\n",
    "\n",
    "class2_epochs = epoch_subject1_class2\n",
    "\n",
    "class3_epochs = epoch_subject1_class3\n",
    "\n",
    "class4_epochs = epoch_subject1_class4\n",
    "\n",
    "temp1_epo1 = append_epo(class1_epochs,class2_epochs)\n",
    "temp2_epo2 = append_epo(class3_epochs,class4_epochs)\n",
    "final_epoch = append_epo(temp1_epo1,temp2_epo2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class1_epochs.axes[0].size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Build the two dictionaries\n",
    "\n",
    "\n",
    "# Dictionary with band power features\n",
    "#form the dictionary using bandpower features where each column is a data point.\n",
    "\n",
    "#For class 1\n",
    "dictionary1 = []\n",
    "dictionary2 = []\n",
    "targets_bp = []\n",
    "targets_we = []\n",
    "for i in range(len(final_epoch.axes[0])):\n",
    "    segment = final_epoch.data[i]\n",
    "    segment = np.array(segment)\n",
    "    segment = np.transpose(segment)\n",
    "    \n",
    "    #features = dct_features(segment)\n",
    "    features1 = bandpowers(segment)\n",
    "    #features = logvariance(segment)\n",
    "    \n",
    "    features2 = wavelet_features(segment)\n",
    "    f1 = np.array(features1)\n",
    "    f2 = np.array(features2)\n",
    "    if(not(np.isnan(f1).any())):\n",
    "        dictionary1.append(features1)\n",
    "        targets_bp.append(final_epoch.axes[0][i])\n",
    "    \n",
    "    if(not(np.isnan(f2).any())):\n",
    "        dictionary2.append(features2)\n",
    "        targets_we.append(final_epoch.axes[0][i])\n",
    "    \n",
    "    \n",
    "dictionary1 = np.array(dictionary1)\n",
    "dictionary2 = np.array(dictionary2)\n",
    "\n",
    "\n",
    "dictionary_bandpower  = dictionary1\n",
    "dictionary_wavelet = dictionary2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#For wavelet\n",
    "\n",
    "from scipy.sparse import coo_matrix\n",
    "X_sparse = coo_matrix(dictionary_wavelet)\n",
    "\n",
    "from sklearn.utils import resample\n",
    "dictionary_wavelet, X_sparse, y_we = resample(dictionary_wavelet, X_sparse,targets_we , random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#For Band Power\n",
    "\n",
    "from scipy.sparse import coo_matrix\n",
    "X_sparse = coo_matrix(dictionary_bandpower)\n",
    "\n",
    "from sklearn.utils import resample\n",
    "dictionary_bandpower, X_sparse, y_bp = resample(dictionary_bandpower, X_sparse,targets_bp , random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_accuracy(Xts,yts,D,minimum):\n",
    "    y_pred1 = []\n",
    "    y_pred2 = []\n",
    "    y_pred3 = []\n",
    "    y_pred4 = []\n",
    "    diff = []\n",
    "    class1_avg = 0\n",
    "    class2_avg = 0\n",
    "    class3_avg = 0\n",
    "    class4_avg = 0\n",
    "    counter1 = 0\n",
    "    for i in range(len(Xts)):\n",
    "        features = Xts[i]\n",
    "        \n",
    "        omp = OrthogonalMatchingPursuit(n_nonzero_coefs=75)\n",
    "        omp.fit(D,features)\n",
    "        coef = omp.coef_\n",
    "        \n",
    "        s1 = 0\n",
    "        s2 = 0\n",
    "        s3 = 0\n",
    "        s4 = 0\n",
    "        \n",
    "        l1 = 0\n",
    "        l2 = 0\n",
    "        l3 = 0\n",
    "        l4 = 0\n",
    "        \n",
    "        \n",
    "        a1 = 0\n",
    "        a2 = 0\n",
    "        a3 = 0\n",
    "        a4 = 0\n",
    "        \n",
    "        \n",
    "        \n",
    "        list1 = coef[0:minimum]\n",
    "        list2 = coef[minimum:2*minimum]\n",
    "        list3 = coef[2*minimum:3*minimum]\n",
    "        list4 = coef[3*minimum:4*minimum]\n",
    "        \n",
    "        \n",
    "        \n",
    "        c1 = (sum(z*z for z in list1))**(1/2.0) \n",
    "        c2 = (sum(z*z for z in list2))**(1/2.0) \n",
    "        c3 = (sum(z*z for z in list3))**(1/2.0)\n",
    "        c4 = (sum(z*z for z in list4))**(1/2.0) \n",
    "        \n",
    "        s1 = np.std(list1)\n",
    "        s2 = np.std(list2)\n",
    "        s3 = np.std(list3)\n",
    "        s4 = np.std(list4)\n",
    "        \n",
    "        a1 = max(list1)\n",
    "        a2 = max(list2)\n",
    "        a3 = max(list3)\n",
    "        a4 = max(list4)\n",
    "        \n",
    "        for i1 in range(minimum):\n",
    "            l1 = l1 + coef[i1]\n",
    "        \n",
    "        for i1 in xrange(minimum,2*minimum):\n",
    "            l2 = l2 + coef[i1]\n",
    "        \n",
    "        for i1 in range(2*minimum,3*minimum):\n",
    "            l3 = l3 + coef[i1]\n",
    "        \n",
    "        for i1 in xrange(3*minimum,4*minimum):\n",
    "            l4 = l4 + coef[i1]\n",
    "        \n",
    "        if s1 >= s2 and s1>= s3 and s1>=s4:\n",
    "            y_pred1.append(0)\n",
    "        elif s2 >= s1 and s2>= s3 and s2>=s4:\n",
    "            y_pred1.append(1)\n",
    "        elif s3>=s1 and s3>=s2 and s3>=s4:\n",
    "            y_pred1.append(2)\n",
    "        else:\n",
    "            y_pred1.append(3)\n",
    "            if(yts[i] == 2):\n",
    "                if(counter1==0):\n",
    "                    counter1 +=1\n",
    "                    idx_r, = coef.nonzero()\n",
    "                    plt.xlim(0, len(coef))\n",
    "                    plt.title(\"Sparse Signal\")\n",
    "                    plt.stem(idx_r, coef[idx_r],format='eps', dpi=1000)\n",
    "                    #plt.savefig('Results/With 0.2s /sparse+'counter1'.eps', format='eps', dpi=1000)\n",
    "                    plt.show()\n",
    "            \n",
    "        \n",
    "        if l1 >= l2 and l1>= l3 and l1>=l4:\n",
    "            y_pred2.append(0)\n",
    "        elif l2 >= l1 and l2>= l3 and l2>=l4:\n",
    "            y_pred2.append(1)\n",
    "        elif l3>=l1 and l3>=l2 and l3>=l4:\n",
    "            y_pred2.append(2)\n",
    "        else:\n",
    "            y_pred2.append(3)\n",
    "        \n",
    "        \n",
    "        if a1 >= a2 and a1>= a3 and a1>=a4:\n",
    "            y_pred3.append(0)\n",
    "        elif a2 >= a1 and a2>= a3 and a2>=a4:\n",
    "            y_pred3.append(1)\n",
    "        elif a3>=a1 and a3>=a2 and a3>=a4:\n",
    "            y_pred3.append(2)\n",
    "        else:\n",
    "            y_pred3.append(3)\n",
    "            \n",
    "        if c1 >= c2 and c1>= c3 and c1>=c4:\n",
    "            y_pred4.append(0)\n",
    "        elif c2 >= c1 and c2>= c3 and c2>=c4:\n",
    "            y_pred4.append(1)\n",
    "        elif c3>=c1 and c3>=c2 and c3>=c4:\n",
    "            y_pred4.append(2)\n",
    "        else:\n",
    "            y_pred4.append(3)\n",
    "            \n",
    "    \n",
    "    print('class1', metrics.accuracy_score(yts, y_pred4, normalize=True, sample_weight=None))  \n",
    "    class1_avg += metrics.accuracy_score(yts, y_pred4, normalize=True, sample_weight=None)\n",
    "    \n",
    "    print('class2', metrics.accuracy_score(yts, y_pred3, normalize=True, sample_weight=None)) \n",
    "    class2_avg += metrics.accuracy_score(yts, y_pred3, normalize=True, sample_weight=None)\n",
    "    \n",
    "    print('class3', metrics.accuracy_score(yts, y_pred1, normalize=True, sample_weight=None))\n",
    "    class3_avg += metrics.accuracy_score(yts, y_pred1, normalize=True, sample_weight=None)\n",
    "    \n",
    "    print('class4',metrics.accuracy_score(yts, y_pred2, normalize=True, sample_weight=None))\n",
    "    class4_avg += metrics.accuracy_score(yts, y_pred2, normalize=True, sample_weight=None)\n",
    "    \n",
    "    print('\\n')\n",
    "    \n",
    "    \n",
    "    return y_pred4,y_pred3,y_pred1,y_pred2,class1_avg,class2_avg,class3_avg,class4_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## K fold cross validation \n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "#dictionary = dictionary_bandpower\n",
    "dictionary = dictionary_wavelet\n",
    "#dictionary = dictionary_dct\n",
    "\n",
    "kf = KFold(n_splits=10,random_state = 30, shuffle = True)\n",
    "kf.get_n_splits(dictionary)\n",
    "\n",
    "y =np.array(y_we)\n",
    "\n",
    "\n",
    "y_classifier1 = []\n",
    "y_classifier2 = []\n",
    "y_classifier3 = []\n",
    "y_classifier4 = []\n",
    "\n",
    "avg1 = 0\n",
    "avg2 = 0\n",
    "avg3 = 0\n",
    "avg4 = 0\n",
    "\n",
    "a1 = 0;\n",
    "a2 = 0;\n",
    "a3 = 0;\n",
    "a4 = 0;\n",
    "minimum = 0;\n",
    "\n",
    "\n",
    "y_all1 = []\n",
    "y_all2 = []\n",
    "y_all3 = []\n",
    "y_all4 = []\n",
    "y_example_test = []\n",
    "\n",
    "reb_dictionary = [];\n",
    "\n",
    "\n",
    "y_final_test = []\n",
    " \n",
    "print(kf)\n",
    "\n",
    "\n",
    "for train_index, test_index in kf.split(dictionary):\n",
    "    X_train, X_test = dictionary[train_index], dictionary[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    class1 = 0\n",
    "    class2 = 0\n",
    "    class3 = 0\n",
    "    class4 = 0\n",
    "    for i in range(len(y_train)):\n",
    "        if(y_train[i] == 0):\n",
    "            class1 += 1;\n",
    "        elif(y_train[i] == 1):\n",
    "            class2 += 1;\n",
    "        elif(y_train[i] == 2):\n",
    "            class3 += 1;\n",
    "        else:\n",
    "            class4 += 1;\n",
    "            \n",
    "    minimum = min(min(class1,class2),min(class3,class4)) \n",
    "    reb_y = []\n",
    "    reb_dic = []\n",
    "    count = 0\n",
    "    iterator = 0\n",
    "    while(count < minimum):\n",
    "        if y_train[iterator] == 0:\n",
    "            reb_dic.append(X_train[iterator])\n",
    "            reb_y.append(0)\n",
    "            count += 1\n",
    "        iterator += 1\n",
    "    \n",
    "    count = 0\n",
    "    iterator = 0\n",
    "    while(count < minimum):\n",
    "        if y_train[iterator] == 1:\n",
    "            reb_dic.append(X_train[iterator])\n",
    "            reb_y.append(1)\n",
    "            count += 1\n",
    "        iterator += 1\n",
    "        \n",
    "    count = 0\n",
    "    iterator = 0\n",
    "    while(count < minimum):\n",
    "        if y_train[iterator] == 2:\n",
    "            reb_dic.append(X_train[iterator])\n",
    "            reb_y.append(2)\n",
    "            count += 1\n",
    "        iterator += 1\n",
    "    \n",
    "    count = 0\n",
    "    iterator = 0\n",
    "    while(count < minimum):\n",
    "        if y_train[iterator] == 3:\n",
    "            reb_dic.append(X_train[iterator])\n",
    "            reb_y.append(3)\n",
    "            count += 1\n",
    "        iterator += 1\n",
    "        \n",
    "    \n",
    "    reb_dictionary = np.array(reb_dic)\n",
    "    reb_dictionary = reb_dictionary.transpose()\n",
    "    \n",
    "    \n",
    "    y_classifier1,y_classifier2,y_classifier3,y_classifier4,a1, a2, a3, a4 = calculate_accuracy(X_test,y_test,reb_dictionary,minimum)\n",
    "    \n",
    "     \n",
    "    y_all1.extend(y_classifier1);\n",
    "    y_all2.extend(y_classifier2);\n",
    "    y_all3.extend(y_classifier3);\n",
    "    y_all4.extend(y_classifier4);\n",
    "    \n",
    "    y_final_test.extend(y_test);\n",
    "    \n",
    "    \n",
    "    avg1 += a1;\n",
    "    avg2 += a2;\n",
    "    avg3 += a3;\n",
    "    avg4 += a4;\n",
    "    \n",
    "    \n",
    "print('class1_average:',avg1/10)\n",
    "print('class2_average:',avg2/10)\n",
    "print('class3_average:',avg3/10)\n",
    "print('class4_average:',avg4/10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dictionary.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plot confusion matrix\n",
    "\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Greens):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnf_matrix = confusion_matrix(y_final_test, y_all4)\n",
    "np.set_printoptions(precision=2)\n",
    "class_names = [\"Left\",\"Right\",\"Foot\",\"Tongue\"]\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,title='Confusion matrix, without normalization')\n",
    "#plt.savefig('Results/With 0.2s /CM_WN_S3.eps', format='eps', dpi=1000)\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,title='Normalized confusion matrix')\n",
    "#plt.savefig('Results/With 0.2s /CM_N_S3.eps', format='eps', dpi=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Plot ROC curve\n",
    "\n",
    "count = 0\n",
    "iterator = 0\n",
    "real0 = []\n",
    "pred0 = []\n",
    "\n",
    "real1 = []\n",
    "pred1 = []\n",
    "\n",
    "\n",
    "real2 = []\n",
    "pred2 = []\n",
    "\n",
    "\n",
    "real3 = []\n",
    "pred3 = []\n",
    "\n",
    "while(iterator < len(y_final_test)):\n",
    "    if(y_final_test[iterator] == 0):\n",
    "        real0.append(0)\n",
    "        if(y_all1[iterator] == 0):\n",
    "            pred0.append(0)\n",
    "        else:\n",
    "            pred0.append(1)\n",
    "    else:\n",
    "        real0.append(1)\n",
    "        if(y_all1[iterator] == 0):\n",
    "            pred0.append(0)\n",
    "        else:\n",
    "            pred0.append(1)\n",
    "    iterator += 1\n",
    "    \n",
    "iterator = 0\n",
    "while(iterator < len(y_final_test)):\n",
    "    if(y_final_test[iterator] == 1):\n",
    "        real1.append(1)\n",
    "        if(y_all1[iterator] == 1):\n",
    "            pred1.append(1)\n",
    "        else:\n",
    "            pred1.append(0)\n",
    "    else:\n",
    "        real1.append(0)\n",
    "        if(y_all1[iterator] == 1):\n",
    "            pred1.append(1)\n",
    "        else:\n",
    "            pred1.append(0)\n",
    "    iterator += 1\n",
    "    \n",
    "    \n",
    "iterator = 0\n",
    "while(iterator < len(y_final_test)):\n",
    "    if(y_final_test[iterator] == 2):\n",
    "        real2.append(1)\n",
    "        if(y_all1[iterator] == 2):\n",
    "            pred2.append(1)\n",
    "        else:\n",
    "            pred2.append(0)\n",
    "    else:\n",
    "        real2.append(0)\n",
    "        if(y_all1[iterator] == 2):\n",
    "            pred2.append(1)\n",
    "        else:\n",
    "            pred2.append(0)\n",
    "    iterator += 1\n",
    "\n",
    "iterator = 0\n",
    "while(iterator < len(y_final_test)):\n",
    "    if(y_final_test[iterator] == 3):\n",
    "        real3.append(1)\n",
    "        if(y_all1[iterator] == 3):\n",
    "            pred3.append(1)\n",
    "        else:\n",
    "            pred3.append(0)\n",
    "    else:\n",
    "        real3.append(0)\n",
    "        if(y_all1[iterator] == 3):\n",
    "            pred3.append(1)\n",
    "        else:\n",
    "            pred3.append(0)\n",
    "    iterator += 1\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from scipy import interp\n",
    "\n",
    "fpr, tpr, _ = roc_curve(real0, pred0)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "fpr1, tpr1, _ = roc_curve(real1, pred1)\n",
    "roc_auc1 = auc(fpr1, tpr1)\n",
    "\n",
    "fpr2, tpr2, _ = roc_curve(real2, pred2)\n",
    "roc_auc2 = auc(fpr2, tpr2)\n",
    "\n",
    "fpr3, tpr3, _ = roc_curve(real3, pred3)\n",
    "roc_auc3 = auc(fpr3, tpr3)\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='blue',\n",
    "         lw=lw, label='Left class ROC curve (area = %0.2f)' % roc_auc)\n",
    "\n",
    "plt.plot(fpr1, tpr1, color='green',\n",
    "         lw=lw, label='Right class ROC curve (area = %0.2f)' % roc_auc1)\n",
    "\n",
    "plt.plot(fpr2, tpr2, color='red',\n",
    "         lw=lw, label='Foot class ROC curve (area = %0.2f)' % roc_auc2)\n",
    "\n",
    "\n",
    "plt.plot(fpr3, tpr3, color='yellow',\n",
    "         lw=lw, label='Tongue class ROC curve (area = %0.2f)' % roc_auc3)\n",
    "plt.plot([0, 1], [0, 1], color='darkorange', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "#plt.savefig('Results/With 0.2s /ROC_S3.eps', format='eps', dpi=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Plot precision recall curve\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from itertools import cycle\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "\n",
    "# Compute Precision-Recall and plot curve\n",
    "precision = []\n",
    "recall = []\n",
    "average_precision = []\n",
    "\n",
    "precision, recall,thresholds = precision_recall_curve(real0,pred0)\n",
    "\n",
    "average_precision = average_precision_score(real0,pred0)\n",
    "\n",
    "\n",
    "precision1, recall1,thresholds1 = precision_recall_curve(real1,pred1)\n",
    "\n",
    "average_precision1 = average_precision_score(real1,pred1)\n",
    "\n",
    "\n",
    "precision2, recall2,thresholds2 = precision_recall_curve(real2,pred2)\n",
    "\n",
    "average_precision2 = average_precision_score(real2,pred2)\n",
    "\n",
    "\n",
    "precision3, recall3,thresholds3 = precision_recall_curve(real3,pred3)\n",
    "\n",
    "average_precision3 = average_precision_score(real3,pred3)\n",
    "\n",
    "\n",
    "# Plot Precision-Recall curve\n",
    "plt.clf()\n",
    "plt.plot(recall, precision, lw=lw, color='blue', label='Left class Precision-recall curve (area = {0:0.2f})'\n",
    "                   ''.format(average_precision))\n",
    "\n",
    "plt.plot(recall1, precision1, lw=lw, color='green', label='Right class Precision-recall curve (area = {0:0.2f})'\n",
    "                   ''.format(average_precision1))\n",
    "\n",
    "\n",
    "plt.plot(recall2, precision2, lw=lw, color='red', label='Foot class Precision-recall curve (area = {0:0.2f})'\n",
    "                   ''.format(average_precision2))\n",
    "\n",
    "plt.plot(recall3, precision3, lw=lw, color='yellow', label='Tongue class Precision-recall curve (area = {0:0.2f})'\n",
    "                   ''.format(average_precision3))\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title(\"Precision Recall Curve\")\n",
    "\n",
    "plt.legend(loc=\"lower left\")\n",
    "#plt.savefig('Results/With 0.2s /PR_S3.eps', format='eps', dpi=1000)\n",
    "plt.show()\n",
    "#plt.savefig('precision_S3.eps', format='eps', dpi=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
